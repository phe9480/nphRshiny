% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simulation.nphDesign.pwexp.R
\name{simulation.nphDesign.pwexp}
\alias{simulation.nphDesign.pwexp}
\title{Trial Data Simulations and Analysis Using Weighted Log-rank Test For Piecewise Exponential Distribution}
\usage{
simulation.nphDesign.pwexp(
  nSim = 10000,
  N = 672,
  A = 21,
  w = 1.5,
  Lambda = NULL,
  r = 1,
  lambda0 = log(2)/11.7,
  lambda1 = log(2)/11.7 * 0.745,
  cuts = NULL,
  dropOff0 = 0,
  dropOff1 = 0,
  targetEvents = c(290, 397, 496),
  sf = "LDOF",
  param = -3,
  overall.alpha = 0.025,
  alpha = NULL,
  logrank = "N",
  fws.options = NULL,
  H0 = "N",
  parallel = TRUE,
  n.cores = 8,
  seed = 2022
)
}
\arguments{
\item{nSim}{Number of trials}

\item{N}{Total number patients in two arms.}

\item{A}{Total accrual period in months}

\item{w}{Weight parameter in cumulative enrollment pattern.
The cumulative enrollment at month t is (t / A)^w, eg, at month 6,
the enrollment is N*(6/24)^2 = N/16 for 24 months planned accrual period.}

\item{Lambda}{Cumulative distribution function (CDF) for enrollment on (0, infinity). For example, uniform enrollment of 20 patients / month for 24 months has Lambda = function(t){t/24*as.numeric(t<= 24) + as.numeric(t>24)}.}

\item{r}{Randomization ratio r:1, where r refers to the experimental arm, eg, r=2 in 2:1 ratio}

\item{lambda0}{Hazard rates for control arm of intervals defined by cuts; for exponential(lambda0) distribution,
lambda0 = log(2) / median;}

\item{lambda1}{Hazard rates for experimental arm for intervals; for exponential(lambda1) distribution,
lambda1 = log(2) / median; For delayed effect under H1, lambda1 is a vector (below).}

\item{cuts}{Timepoints to form intervals for piecewise exponential distribution. For example,
experimental arm has hr = 0.6 after delay, then cuts = 6, and
lamda0 = log(2) / m0 or lambda0 = rep(log(2) / m0, 2),
lamda1 = c(log(2)/m0, log(2)/m0\emph{hr).
treatment after 24 mo, so its hazard decreases 20\%. Then,
lambda0 = c(log(2)/m0, log(2)/m0, log(2)/m0}0.8),
lambda1 = c(log(2)/m0, log(2)/m0\emph{hr, log(2)/m0}hr), and
cuts = c(6, 24), which forms 3 intervals (0, 6), (6, 24), (24, infinity)}

\item{dropOff0}{Drop Off rate per month, eg, 1\%, for control arm}

\item{dropOff1}{Drop Off rate per month, eg, 1\%, for experimental arm}

\item{targetEvents}{A vector of target events is used to determine DCOs. For example,
397 target events are used to determine IA DCO; and 496 events are used
to determine the FA cutoff.}

\item{sf}{Spending function. LanDeMets O'Brien Fleming: "LDOF", LanDeMets Pocock: "LDPK", "HSD": Hwang-Shih-DeCani spending function with parameter param.}

\item{param}{parameter for Hwang-Shih-DeCani spending function}

\item{overall.alpha}{Allocated overall alpha (one-sided) for group sequential design}

\item{alpha}{Allocated one-sided alpha levels. sum(alpha) is the total type I error.
If alpha spending function a(t) is used for information time c(t1, ..., tK),
then alpha1 = a(t1), alpha2 = a(t2)-a(t1), ..., alphaK = a(tK)-a(t_{K-1}),
and the total alpha for all analyses is a(tK). When alpha is provided, sf is ignored.}

\item{logrank}{Indicator whether log-rank test is requested besides the weighted logrank tests. "Y" or "N". Default "Y".
If "Y", the traditional log-rank test will be used based on survdiff() function.
If "N", the weighted log-rank test with weighting function specified in fws will be used.}

\item{fws.options}{Weighting strategies in the following format as examples. If fws.options is provided,
then the nphDesign object's weighting strategy will be ignored. fws can contain multiple weighting strategies.
For example, fws = list(fws1, fws2) means 2 weighting strategies are evaluated, where
fws1 = list(IA = list(lr), FA=list(lr, fh01)); fws2 = list(IA = list(lr), FA=list(fh01)). Each
weighting strategy is specified as following examples for illustration.
\itemize{
\item (1) Single-time analysis using log-rank test: fws1 = list(FA = list(lr));
\item (2) Two interim analyses and 1 final analysis with logrank at IA1,
max(logrank, fleming-harrington(0,1) at IA2, and
max(logrank, fleming-harrington(0,1), fleming-harrington(1,1)) at final):
fws2 = list(IA1 = list(lr), IA2=list(lr, fh01), FA=list(lr,fh01,fh11)).
\item (3) One IA and one FA: stabilized Fleming-Harrington (0,1) at IA,
and max(logrank, stabilized Fleming-Harrington (0, 1)) at FA.
fw3 = list(IA = list(sfh01), FA=list(lr, sfh01)).
\item General format of weighting strategy specification is: (a) the weight
functions for each analysis must be provided in list() object even there is only
1 weight function for that an analysis. (b) The commonly used functions
are directly available including lr: log-rank test; fh01: Fleming-Harrington (0,1) test;
fh11: Fleming-Harrington(1,1) test; fh55: Fleming-Harrington(0.5, 0.5) test.
stabilized versions at median survival time: sfh01, sfh11, sfh55. Modestly
log-rank test: mlr.
(c) User-defined weight function can also be handled, but the weight function
must be defined as a function of survival rate, i.e., fws = function(s){...},
where s is the survival rate S(t-).
\item Options of weighting strategies for exploration: fws.options=list(fws1, fws2, fws3).
}}

\item{H0}{"Y" or "N" to indicate whether the simulation is for type I error}

\item{parallel}{True/False indicator. If true, use parallel computing weighted log-rank test for each analysis in strategy m}

\item{n.cores}{This will be used if parallelization is TRUE. Default is 8.}

\item{seed}{seed for generating samples. Default 2022}
}
\value{
An object with a dataframe for each analysis including the following variables:
\describe{
\item{power}{Power for each analysis}
\item{overall.power}{Overall power of the group sequential design}
\item{wlr.simulations}{Simulation results for each simulated study data.
An array with dimensions: nSim simulations X M testing strategies
(fws.options) X K analyses X variables:
\itemize{
\item z value
\item p value
\item analysis
\item rejection boundary
\item testing result (1 = positive; 0 = negative)
}}
\item{lr.power}{Power for each analysis using log-rank test. Available if logrank ="Y"}
\item{lr.overall.power}{Overall power of the group sequential design using logrank test}
\item{lr.simulations}{Simulation results for each simulated study data using logrank test}
}
}
\description{
Simulate Randomized two-arm trial data with the following characteristics:
(1) randomization time (entry time) is generated according to the specified non-uniform accrual pattern,
i.e. the cumulative recruitment at calendar time t is (t/A)^w with weight w and enrollment complete in A months.
w = 1 means uniform enrollment, which is usually not realistic due to graduate sites activation process.
(2) Survival time follows piece-wise exponential distribution for each arm.
(3) N total patients with r:1 randomization ratio
(4) Random drop off can be incorporated into the censoring process.
(5) Data cutoff dates are determined by specified vector of target events for all analyses.
(6) A dataset is generated for each analysis according to the specified number of target events.
Multiple analyses can be specified according to the vector of targetEvents, eg, targetEvents = c(100, 200, 300)
defines 3 analyses at 100, 200, and 300 events separately.
(7) Weighted log-rank test is then performed for each simulated group sequential dataset.
}
\examples{
#Example (1): Simulate 10 samples from proportional hazards scenario. 
fws1 = list(IA1 = list(lr), FA = list(lr))
fws2 = list(IA1 = list(lr), FA = list(fh01))
fws3 = list(IA1 = list(fh01), FA = list(fh01))
fws4 = list(IA1 = list(lr), FA = list(lr, fh01))
fws5 = list(IA1 = list(lr), FA = list(lr, fh01, fh11))
fws6 = list(IA1 = list(lr, fh01), FA = list(lr, fh01))
fws7 = list(IA1 = list(sfh01), FA = list(lr, fh01))

#7 weighting strategies for exploration 
fws = list(fws1, fws2, fws3, fws4, fws5, fws6, fws7)

alpha = f.alpha(overall.alpha=0.025, side = 1, sf="LDOF", targetEvents=c(60, 80))
m0 = 11.7
lambda0 = log(2) / m0
h0 = function(t){lambda0}; 
S0 = function(t){exp(-lambda0 * t)}
h1 = function(t){lambda0*0.745}; 
S1 = function(t){exp(-lambda0 *0.745* t)}

F.entry = function(t){(t/21)^1.5*as.numeric(t <= 21) + as.numeric(t > 21)}
G.ltfu = function(t){0}
f.logHR = function(t){log(0.745)}

#study design using weighting strategy 1
wlr.power.maxcombo(T = NULL, events = c(60, 80), alpha=alpha, 
  power = NULL, side = 1, r = 1, n = 100, 
  h0 = h0, S0=S0, h1 = h1, S1= S1, f.logHR = f.logHR, 
  f.ws = fws1, F.entry=F.entry, G.ltfu=G.ltfu)
  
#study design using weighting strategy 2
wlr.power.maxcombo(T = NULL, events = c(60, 80), alpha=alpha, 
  power = NULL, side = 1, r = 1, n = 100, 
  h0 = h0, S0=S0, h1 = h1, S1= S1, f.logHR = f.logHR, 
  f.ws = fws2, F.entry=F.entry, G.ltfu=G.ltfu)
  
#Simulations for exploring 7 weighting strategies
H0 = simulate.nphDesign(nSim=5, N = 100, A = 21, w=1.5, r=1, lambda0=log(2)/11.7, lambda1=log(2)/11.7*0.745,
cuts=NULL, targetEvents = c(60, 80), 
sf = "LDOF", overall.alpha = 0.025, side = 1, alpha = NULL,
logrank="Y", fws=fws5)

}
